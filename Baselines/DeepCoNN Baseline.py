# -*- coding: utf-8 -*-
"""New 2 - DeepCoNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CCIdLt6JyTARKfNuYa_ylJwcoGn5-lnD
"""

# ============================================
# DeepCoNN (Fast Version, Colab-ready)
# Two-tower TextCNN on user/item review docs
# BPR training (implicit)
# Metrics: Recall@K, NDCG@K, MRR, Hit@K, AUC, Accuracy, RMSE
# ============================================

!pip install -q pandas numpy scipy torch==2.3.1 tqdm openpyxl

import os, re, math, random, numpy as np, pandas as pd
from collections import defaultdict, Counter
from tqdm import tqdm
import torch, torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from google.colab import files

# --------------------------
# Repro / device
# --------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# --------------------------
# Load Dataset1
# --------------------------
uploaded = files.upload()
INPUT_FILE = list(uploaded.keys())[0]
print("Using:", INPUT_FILE)

def load_any(path):
    ext = os.path.splitext(path)[1].lower()
    if ext in [".csv", ".txt"]:
        return pd.read_csv(path)
    elif ext in [".xls", ".xlsx"]:
        return pd.read_excel(path)
    else:
        raise ValueError("Upload CSV/XLS/XLSX")

df_raw = load_any(INPUT_FILE)
print("Columns:", list(df_raw.columns))
print(df_raw.head(3))

# --------------------------
# Standardize columns
# --------------------------
def guess_col(df, groups):
    low = {c.lower(): c for c in df.columns}
    for g in groups:
        for c in g:
            if c.lower() in low:
                return low[c.lower()]
    return None

user_col = guess_col(df_raw, [["user","user_id","uid","userid"]])
item_col = guess_col(df_raw, [["item","item_id","iid","movieid","product_id"]])
rating_col = guess_col(df_raw, [["rating","ratings","score","rate"]])
ts_col     = guess_col(df_raw, [["timestamp","time","ts","date","datetime","created_at"]])
text_col   = guess_col(df_raw, [["review","text","review_text","content","comment","body"]])

if user_col is None or item_col is None:
    user_col, item_col = df_raw.columns[:2]
    print("Fallback to first two columns as (user,item):", user_col, item_col)

cols = [user_col, item_col] + ([rating_col] if rating_col else []) + ([ts_col] if ts_col else []) + ([text_col] if text_col else [])
df = df_raw[cols].copy()
df.rename(columns={user_col:"user", item_col:"item"}, inplace=True)
if rating_col: df.rename(columns={rating_col:"rating"}, inplace=True)
if ts_col:     df.rename(columns={ts_col:"timestamp"}, inplace=True)
if text_col:   df.rename(columns={text_col:"review"}, inplace=True)
else:          df["review"] = ""

# Implicit binarization
if "rating" in df.columns:
    df["y"] = (pd.to_numeric(df["rating"], errors="coerce").fillna(0) > 0).astype(int)
else:
    df["y"] = 1
df = df[df["y"] > 0]

# Map IDs
df["user"] = df["user"].astype(str)
df["item"] = df["item"].astype(str)
user2id = {u:i for i,u in enumerate(df["user"].astype("category").cat.categories)}
item2id = {v:i for i,v in enumerate(df["item"].astype("category").cat.categories)}
df["u"] = df["user"].map(user2id)
df["i"] = df["item"].map(item2id)
n_users, n_items = len(user2id), len(item2id)
print(f"#Users={n_users}, #Items={n_items}, #Interactions={len(df)}")

# --------------------------
# Leave-One-Out split
# --------------------------
def leave_one_out_split(df_ui):
    frames=[]
    if "timestamp" in df_ui.columns:
        for u,g in df_ui.groupby("u"):
            frames.append(g.sort_values("timestamp"))
    else:
        for u,g in df_ui.groupby("u"):
            frames.append(g.sample(frac=1.0, random_state=SEED))
    train,val,test=[],[],[]
    for g in frames:
        if len(g)==1: test.append(g.iloc[-1])
        elif len(g)==2: val.append(g.iloc[-2]); test.append(g.iloc[-1])
        else:
            train.extend(list(g.iloc[:-2].itertuples(index=False)))
            val.append(g.iloc[-2]); test.append(g.iloc[-1])
    cols=df_ui.columns
    train=pd.DataFrame(train, columns=cols) if train else df_ui.head(0)
    val  =pd.DataFrame(val,   columns=cols)
    test =pd.DataFrame(test,  columns=cols)
    return train.reset_index(drop=True), val.reset_index(drop=True), test.reset_index(drop=True)

base_cols = ["u","i","review"] + (["timestamp"] if "timestamp" in df.columns else []) + (["rating"] if "rating" in df.columns else [])
train_df, val_df, test_df = leave_one_out_split(df[base_cols])
print("#Train:", len(train_df), "#Val:", len(val_df), "#Test:", len(test_df))

def u2pos(df_):
    d=defaultdict(set)
    for u,i in zip(df_["u"].values, df_["i"].values): d[u].add(i)
    return d
u_train_pos=u2pos(train_df); u_val_pos=u2pos(val_df); u_test_pos=u2pos(test_df)

# --------------------------
# Build User/Item Documents
# --------------------------
def normalize_text(s):
    s = str(s).lower()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return s.strip()

train_df["review"] = train_df["review"].map(normalize_text)
user_docs = defaultdict(list)
item_docs = defaultdict(list)
for u,i,txt in zip(train_df["u"].values, train_df["i"].values, train_df["review"].values):
    if txt:
        user_docs[u].append(txt)
        item_docs[i].append(txt)
user_doc = {u:" ".join(user_docs[u]) if u in user_docs else "" for u in range(n_users)}
item_doc = {i:" ".join(item_docs[i]) if i in item_docs else "" for i in range(n_items)}

# --------------------------
# Tokenizer / Vocabulary
# --------------------------
def tokenize(s): return s.split()
MAX_VOCAB = 30000
MAX_LEN_USER = 150
MAX_LEN_ITEM = 150
PAD, UNK = "<pad>", "<unk>"

counter = Counter()
for text in list(user_doc.values()) + list(item_doc.values()):
    counter.update(tokenize(text))
vocab = [PAD, UNK] + [w for w,_ in counter.most_common(MAX_VOCAB-2)]
stoi = {w:i for i,w in enumerate(vocab)}

def encode(text, max_len):
    ids = [stoi.get(w,1) for w in tokenize(text)][:max_len]
    if len(ids)<max_len:
        ids += [0]*(max_len-len(ids))
    return np.array(ids,dtype=np.int64)

user_seqs = np.stack([encode(user_doc[u], MAX_LEN_USER) for u in range(n_users)],axis=0)
item_seqs = np.stack([encode(item_doc[i], MAX_LEN_ITEM) for i in range(n_items)],axis=0)
user_seqs = torch.tensor(user_seqs,dtype=torch.long,device=device)
item_seqs = torch.tensor(item_seqs,dtype=torch.long,device=device)

# --------------------------
# DeepCoNN model
# --------------------------
class DeepCoNN(nn.Module):
    def __init__(self,vocab_size,emb_dim=64,ks=(3,4),nf=64,mlp_hidden=128,pad_idx=0):
        super().__init__()
        self.shared_embed = nn.Embedding(vocab_size,emb_dim,padding_idx=pad_idx)
        self.user_cnn = nn.ModuleList([nn.Conv1d(emb_dim,nf,k) for k in ks])
        self.item_cnn = nn.ModuleList([nn.Conv1d(emb_dim,nf,k) for k in ks])
        self.drop = nn.Dropout(0.2)
        self.out_dim = nf*len(ks)
        self.mlp = nn.Sequential(
            nn.Linear(2*self.out_dim,mlp_hidden),
            nn.ReLU(),
            nn.Linear(mlp_hidden,1)
        )

    def _encode(self,seqs,convs):
        emb = self.shared_embed(seqs).transpose(1,2)
        xs=[torch.max(F.relu(conv(emb)),dim=2).values for conv in convs]
        z=torch.cat(xs,dim=1)
        return self.drop(z)

    def score(self,users,items):
        u_seq=user_seqs[users]; i_seq=item_seqs[items]
        u_vec=self._encode(u_seq,self.user_cnn)
        i_vec=self._encode(i_seq,self.item_cnn)
        x=torch.cat([u_vec,i_vec],dim=1)
        s=self.mlp(x).squeeze(-1)
        return s

    @torch.no_grad()
    def user_item_scores(self,u,item_ids,batch=512):
        scores=[]
        for b in range(0,len(item_ids),batch):
            ids=item_ids[b:b+batch]
            u_seq=user_seqs[u].unsqueeze(0).repeat(len(ids),1)
            i_seq=item_seqs[ids]
            u_vec=self._encode(u_seq,self.user_cnn)
            i_vec=self._encode(i_seq,self.item_cnn)
            x=torch.cat([u_vec,i_vec],dim=1)
            s=self.mlp(x).squeeze(-1)
            scores.append(s.detach().cpu().numpy())
        return np.concatenate(scores,axis=0)

model=DeepCoNN(len(stoi)).to(device)
opt=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-6)
scaler=GradScaler(enabled=(device.type=="cuda"))

# --------------------------
# Helpers
# --------------------------
def sample_bpr_batch(u_pos_dict,n_items,batch_size=2048):
    keys=[u for u,v in u_pos_dict.items() if len(v)>0]
    users,pos,neg=[],[],[]
    for _ in range(batch_size):
        u=random.choice(keys)
        i_pos=random.choice(tuple(u_pos_dict[u]))
        while True:
            j=random.randint(0,n_items-1)
            if j not in u_pos_dict[u]: break
        users.append(u); pos.append(i_pos); neg.append(j)
    return (torch.tensor(users,device=device),
            torch.tensor(pos,device=device),
            torch.tensor(neg,device=device))

def bpr_loss(pos,neg): return -F.logsigmoid(pos-neg).mean()

@torch.no_grad()
def evaluate(model,train_pos,eval_pos,K_list=(10,20),sample_neg=1000):
    metrics={f"{m}@{k}":[] for k in K_list for m in ["Recall","NDCG","MRR","Hit"]}
    all_items=np.arange(n_items)
    for u,pos_set in eval_pos.items():
        pos_items=list(pos_set)
        if not pos_items: continue
        seen=train_pos.get(u,set())
        neg_pool=np.setdiff1d(all_items,np.array(list(seen)))
        neg_cands=np.random.choice(neg_pool,size=min(sample_neg,len(neg_pool)),replace=False) if len(neg_pool)>0 else np.array([],int)
        candidates=np.unique(np.concatenate([neg_cands,np.array(pos_items)]))
        cand_t=torch.tensor(candidates,dtype=torch.long,device=device)
        scores=model.user_item_scores(u,cand_t,batch=256)
        order=np.argsort(-scores); ranked=candidates[order]
        for K in K_list:
            topk=ranked[:K]
            hits=[1 if i in pos_items else 0 for i in topk]
            metrics[f"Recall@{K}"].append(sum(hits)/len(pos_items))
            idcg=sum(1/math.log2(i+2) for i in range(min(len(pos_items),K)))
            dcg=sum(1/math.log2(idx+2) for idx,it in enumerate(topk) if it in pos_items)
            ndcg=dcg/idcg if idcg>0 else 0
            rr=0
            for idx,it in enumerate(ranked):
                if it in pos_items: rr=1/(idx+1); break
            metrics[f"NDCG@{K}"].append(ndcg)
            metrics[f"MRR@{K}"].append(rr)
            metrics[f"Hit@{K}"].append(1 if any(hits) else 0)
    return {m:float(np.mean(v)) for m,v in metrics.items()}

@torch.no_grad()
def auc_score(model,train_pos,eval_pos,neg_per_pos=50):
    aucs=[]
    for u,pos_set in eval_pos.items():
        pos_items=list(pos_set)
        if not pos_items: continue
        seen=train_pos.get(u,set())
        all_negs=[j for j in range(n_items) if j not in seen]
        if len(all_negs)==0: continue
        negs=random.sample(all_negs,min(neg_per_pos,len(all_negs)))
        pos_t=torch.tensor(pos_items,device=device)
        neg_t=torch.tensor(negs,device=device)
        sp=model.user_item_scores(u,pos_t)
        sn=model.user_item_scores(u,neg_t)
        wins=sum(p>n for p in sp for n in sn)
        total=len(sp)*len(sn)
        if total>0: aucs.append(wins/total)
    return float(np.mean(aucs)) if aucs else 0.0

@torch.no_grad()
def accuracy_score(model,eval_df,threshold=0.5):
    users,items=eval_df["u"].values,eval_df["i"].values
    preds=[]
    for u,i in zip(users,items):
        s=model.user_item_scores(u,torch.tensor([i],device=device))[0]
        preds.append(s)
    preds=np.array(preds)
    preds_norm=(preds-preds.min())/(preds.max()-preds.min()+1e-8)
    if "rating" in eval_df.columns:
        labels=(pd.to_numeric(eval_df["rating"],errors="coerce").fillna(0).values>0).astype(int)
    else: labels=np.ones_like(preds_norm)
    preds_bin=(preds_norm>=threshold).astype(int)
    return float((preds_bin==labels).mean())

@torch.no_grad()
def rmse_score(model,eval_df):
    users,items=eval_df["u"].values,eval_df["i"].values
    preds=[]
    for u,i in zip(users,items):
        s=model.user_item_scores(u,torch.tensor([i],device=device))[0]
        preds.append(s)
    preds=np.array(preds)
    if "rating" in eval_df.columns:
        labels=pd.to_numeric(eval_df["rating"],errors="coerce").fillna(0).values.astype(float)
    else: labels=np.ones_like(preds)
    preds_scaled=(preds-preds.min())/(preds.max()-preds.min()+1e-8)*(labels.max()-labels.min())+labels.min()
    return float(np.sqrt(np.mean((preds_scaled-labels)**2)))

# --------------------------
# Train DeppCoNN
# --------------------------
EPOCHS=12
BATCH_SIZE=4096
eval_every=3

print("Start training DeepCoNN (fast)...")
for epoch in range(1,EPOCHS+1):
    model.train()
    users,pos_items,neg_items=sample_bpr_batch(u_train_pos,n_items,BATCH_SIZE)
    if users.numel()==0: break
    opt.zero_grad(set_to_none=True)
    with autocast(enabled=(device.type=="cuda")):
        pos_scores=model.score(users,pos_items)
        neg_scores=model.score(users,neg_items)
        loss=bpr_loss(pos_scores,neg_scores)
    scaler.scale(loss).backward()
    scaler.step(opt)
    scaler.update()
    if epoch%eval_every==0 or epoch==1:
        model.eval()
        val_metrics=evaluate(model,u_train_pos,u_val_pos,K_list=(10,20))
        val_auc=auc_score(model,u_train_pos,u_val_pos)
        val_acc=accuracy_score(model,val_df)
        val_rmse=rmse_score(model,val_df)
        print(f"[Ep{epoch:02d}] Loss={loss.item():.4f} | "
              f"R@10={val_metrics['Recall@10']:.3f} N@10={val_metrics['NDCG@10']:.3f} "
              f"MRR@10={val_metrics['MRR@10']:.3f} AUC={val_auc:.3f} Acc={val_acc:.3f} RMSE={val_rmse:.3f}")

# --------------------------
# Final Test Evaluation
# --------------------------
print("\nFinal evaluation on TEST:")
model.eval()
test_metrics=evaluate(model,u_train_pos,u_test_pos,K_list=(10,20))
test_auc=auc_score(model,u_train_pos,u_test_pos)
test_acc=accuracy_score(model,test_df)
test_rmse=rmse_score(model,test_df)
res={
 "Recall@10":test_metrics["Recall@10"],"NDCG@10":test_metrics["NDCG@10"],"MRR@10":test_metrics["MRR@10"],
 "Hit@10":test_metrics["Hit@10"],"Recall@20":test_metrics["Recall@20"],"NDCG@20":test_metrics["NDCG@20"],
 "MRR@20":test_metrics["MRR@20"],"Hit@20":test_metrics["Hit@20"],"AUC":test_auc,"Accuracy":test_acc,"RMSE":test_rmse
}
print(pd.DataFrame([res]).round(4).to_string(index=False))